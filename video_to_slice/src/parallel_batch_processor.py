#!/usr/bin/env python3
"""
AI Video Master 5.0 - å¹¶è¡Œæ‰¹é‡è§†é¢‘å¤„ç†å™¨ (ç²¾ç®€ç‰ˆ)
ä¸“æ³¨äºå¹¶è¡Œå¤„ç†ï¼Œç§»é™¤æ‰€æœ‰ä¸²è¡Œå¤„ç†ä»£ç 

ä¸»è¦ç‰¹æ€§:
1. å¼‚æ­¥å¹¶è¡Œå¤„ç†å¤šä¸ªè§†é¢‘æ–‡ä»¶
2. ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡ï¼ˆéµå¾ªAPIé…é¢é™åˆ¶ï¼‰
3. FFmpegå¹¶è¡Œåˆ‡ç‰‡ä¼˜åŒ–
4. å®æ—¶è¿›åº¦ç›‘æ§å’Œé”™è¯¯å¤„ç†
5. é‡è¯•æœºåˆ¶å’Œå®¹é”™å¤„ç†
6. è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
"""

import asyncio
import json
import logging
import os
import sys
import time
import argparse
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from tenacity import retry, wait_random_exponential, stop_after_attempt

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('parallel_video_slice.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

try:
    from google_video_analyzer import GoogleVideoAnalyzer
    from parallel_video_slicer import ParallelVideoSlicer
except ImportError as e:
    logger.error(f"ä¾èµ–æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    logger.error("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)


class ParallelBatchProcessor:
    """å¹¶è¡Œæ‰¹é‡è§†é¢‘åˆ‡ç‰‡å¤„ç†å™¨ - ç²¾ç®€ç‰ˆ"""
    
    def __init__(self, output_dir: str = "./output_slices", temp_dir: str = "./temp", 
                 max_concurrent: int = 3, ffmpeg_workers: int = 4):
        """
        åˆå§‹åŒ–å¹¶è¡Œæ‰¹é‡è§†é¢‘åˆ‡ç‰‡å¤„ç†å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            temp_dir: ä¸´æ—¶ç›®å½•
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤3ï¼Œéµå¾ªGoogle Cloud APIé…é¢é™åˆ¶ï¼‰
            ffmpeg_workers: FFmpegå¹¶è¡Œåˆ‡ç‰‡å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤4ï¼‰
        """
        self.output_dir = Path(output_dir)
        self.temp_dir = Path(temp_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.temp_dir.mkdir(exist_ok=True)
        
        # å¹¶å‘æ§åˆ¶
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.analyzer = GoogleVideoAnalyzer()
        self.parallel_slicer = ParallelVideoSlicer(max_workers=ffmpeg_workers)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_videos": 0,
            "processed_videos": 0,
            "failed_videos": 0,
            "total_slices": 0,
            "processing_errors": []
        }
        
        logger.info(f"åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨ - æœ€å¤§å¹¶å‘æ•°: {max_concurrent}, FFmpegå·¥ä½œçº¿ç¨‹: {ffmpeg_workers}")
    
    def _validate_video_file(self, video_path: str) -> bool:
        """éªŒè¯è§†é¢‘æ–‡ä»¶"""
        try:
            if not os.path.exists(video_path):
                return False
            
            file_size = os.path.getsize(video_path)
            if file_size == 0:
                return False
            
            # ç®€å•çš„æ–‡ä»¶æ ¼å¼æ£€æŸ¥
            valid_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv'}
            if Path(video_path).suffix.lower() not in valid_extensions:
                return False
            
            return True
        except Exception:
            return False
    
    def _create_default_shots(self, video_path: str, segment_duration: float = 10.0) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºé»˜è®¤çš„æ—¶é—´æ®µåˆ‡ç‰‡ï¼ˆå½“æ— æ³•æ£€æµ‹åˆ°é•œå¤´æ—¶ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            segment_duration: æ¯ä¸ªç‰‡æ®µçš„æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            é»˜è®¤åˆ‡ç‰‡åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ffprobeè·å–è§†é¢‘æ—¶é•¿
            import subprocess
            cmd = [
                "ffprobe", "-v", "quiet", "-show_entries", "format=duration",
                "-of", "csv=p=0", video_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode != 0:
                logger.error(f"æ— æ³•è·å–è§†é¢‘æ—¶é•¿: {video_path}")
                return []
            
            duration = float(result.stdout.strip())
            if duration <= 0:
                return []
            
            shots = []
            current_time = 0
            index = 1
            
            while current_time < duration:
                end_time = min(current_time + segment_duration, duration)
                
                shots.append({
                    'index': index,
                    'start_time': current_time,
                    'end_time': end_time,
                    'duration': end_time - current_time,
                    'type': f'é»˜è®¤ç‰‡æ®µ{index}',
                    'confidence': 0.8
                })
                
                current_time = end_time
                index += 1
            
            logger.info(f"åˆ›å»ºé»˜è®¤åˆ‡ç‰‡æ–¹æ¡ˆ: {len(shots)} ä¸ªç‰‡æ®µï¼Œæ¯ä¸ª {segment_duration} ç§’")
            return shots
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé»˜è®¤åˆ‡ç‰‡å¤±è´¥: {e}")
            return []
    
    def _validate_slice_quality(self, slices: List[Dict[str, Any]], video_name: str) -> Dict[str, Any]:
        """éªŒè¯åˆ‡ç‰‡è´¨é‡"""
        if not slices:
            return {
                "passed": False,
                "error": "æ²¡æœ‰ç”Ÿæˆä»»ä½•åˆ‡ç‰‡",
                "details": {}
            }
        
        # åŸºæœ¬è´¨é‡æ£€æŸ¥
        total_slices = len(slices)
        valid_slices = 0
        total_duration = 0
        
        for slice_info in slices:
            if 'file_path' in slice_info and os.path.exists(slice_info['file_path']):
                file_size = os.path.getsize(slice_info['file_path'])
                if file_size > 1024:  # è‡³å°‘1KB
                    valid_slices += 1
                    total_duration += slice_info.get('duration', 0)
        
        success_rate = (valid_slices / total_slices) * 100 if total_slices > 0 else 0
        
        return {
            "passed": success_rate >= 80,  # 80%æˆåŠŸç‡ä¸ºé€šè¿‡
            "success_rate": success_rate,
            "total_slices": total_slices,
            "valid_slices": valid_slices,
            "total_duration": total_duration,
            "error": f"æˆåŠŸç‡è¿‡ä½: {success_rate:.1f}%" if success_rate < 80 else None,
            "details": {
                "video_name": video_name,
                "quality_threshold": 80,
                "check_time": datetime.now().isoformat()
            }
        }
    
    def process_video(self, video_path: str, features: List[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆå¹¶è¡Œåˆ‡ç‰‡ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            features: åˆ†æåŠŸèƒ½åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æœ
        """
        video_name = Path(video_path).stem
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_name}")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            
            # éªŒè¯è§†é¢‘æ–‡ä»¶
            if not self._validate_video_file(video_path):
                raise Exception("è§†é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥")
            
            # åˆ›å»ºè§†é¢‘ä¸“ç”¨è¾“å‡ºç›®å½•
            video_output_dir = self.output_dir / video_name
            video_output_dir.mkdir(exist_ok=True)
            
            # è®¾ç½®é»˜è®¤åˆ†æåŠŸèƒ½ - åªä½¿ç”¨é•œå¤´æ£€æµ‹ä»¥æå‡æ€§èƒ½
            if not features:
                features = ["shot_detection"]
            
            # åˆ†æè§†é¢‘
            logger.info(f"åˆ†æè§†é¢‘å†…å®¹: {video_name}")
            analysis_result = self.analyzer.analyze_video(
                video_path=video_path,
                features=features,
                auto_cleanup_storage=True
            )
            
            if not analysis_result.get("success"):
                error_msg = analysis_result.get("error", "åˆ†æå¤±è´¥")
                raise Exception(f"è§†é¢‘åˆ†æå¤±è´¥: {error_msg}")
            
            # æå–é•œå¤´ä¿¡æ¯
            shots = self.analyzer.extract_shots(analysis_result)
            if not shots:
                logger.warning(f"æœªæ£€æµ‹åˆ°é•œå¤´ï¼Œä½¿ç”¨é»˜è®¤åˆ†å‰²æ–¹æ¡ˆ: {video_name}")
                shots = self._create_default_shots(video_path)
            
            logger.info(f"æ£€æµ‹åˆ° {len(shots)} ä¸ªé•œå¤´")
            
            # ğŸš€ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨å¹¶è¡Œåˆ‡ç‰‡å™¨ç”Ÿæˆè§†é¢‘åˆ‡ç‰‡
            logger.info(f"å¼€å§‹å¹¶è¡Œç”Ÿæˆè§†é¢‘åˆ‡ç‰‡: {video_name}")
            
            def progress_callback(progress, message):
                logger.info(f"åˆ‡ç‰‡è¿›åº¦ {progress}%: {message}")
            
            slice_results = self.parallel_slicer.create_slices_from_shots(
                video_path=video_path,
                shots=shots,
                video_name=video_name,
                output_dir=str(self.output_dir),
                progress_callback=progress_callback
            )
            
            # éªŒè¯åˆ‡ç‰‡è´¨é‡
            quality_result = self._validate_slice_quality(slice_results, video_name)
            
            if not quality_result["passed"]:
                logger.warning(f"åˆ‡ç‰‡è´¨é‡ä¸ç¬¦åˆæ ‡å‡†: {quality_result['error']}")
            
            # ä¿å­˜åˆ‡ç‰‡ä¿¡æ¯
            slice_info_file = video_output_dir / f"{video_name}_slices.json"
            with open(slice_info_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'video_name': video_name,
                    'video_path': video_path,
                    'analysis_features': features,
                    'total_shots': len(shots),
                    'successful_slices': len(slice_results),
                    'quality_check': quality_result,
                    'slices': slice_results,
                    'processing_time': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_slices"] += len(slice_results)
            
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {video_name}ï¼Œç”Ÿæˆ {len(slice_results)} ä¸ªåˆ‡ç‰‡")
            
            return {
                "success": True,
                "video_name": video_name,
                "slices_count": len(slice_results),
                "slices": slice_results,
                "quality_check": quality_result,
                "output_dir": str(video_output_dir)
            }
            
        except Exception as e:
            error_msg = f"å¤„ç†è§†é¢‘å¤±è´¥ {video_name}: {str(e)}"
            logger.error(error_msg)
            self.stats["processing_errors"].append({
                "video": video_name,
                "error": error_msg
            })
            
            return {
                "success": False,
                "video_name": video_name,
                "error": error_msg,
                "slices_count": 0,
                "slices": []
            }
    
    @retry(
        wait=wait_random_exponential(multiplier=1, max=120),
        stop=stop_after_attempt(3)
    )
    async def async_process_video(self, video_path: str, features: List[str] = None) -> Dict[str, Any]:
        """
        å¼‚æ­¥å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            features: åˆ†æåŠŸèƒ½åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            video_name = Path(video_path).stem
            
            try:
                logger.info(f"ğŸ¬ å¼€å§‹å¼‚æ­¥å¤„ç†è§†é¢‘: {video_name}")
                start_time = time.time()
                
                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥çš„è§†é¢‘å¤„ç†
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None, 
                    self.process_video, 
                    video_path, 
                    features
                )
                
                end_time = time.time()
                duration = end_time - start_time
                
                if result.get("success"):
                    logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: {video_name} ({duration:.1f}ç§’)")
                else:
                    logger.error(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {video_name}")
                
                return result
                
            except Exception as e:
                error_msg = f"å¼‚æ­¥å¤„ç†è§†é¢‘å¤±è´¥ {video_name}: {str(e)}"
                logger.error(error_msg)
                return {
                    "success": False,
                    "video_name": video_name,
                    "error": error_msg,
                    "slices_count": 0,
                    "slices": []
                }
    
    async def parallel_batch_process(self, video_files: List[str], 
                                   features: List[str] = None,
                                   progress_callback: Optional[callable] = None) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰¹é‡å¤„ç†è§†é¢‘æ–‡ä»¶
        
        Args:
            video_files: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            features: åˆ†æåŠŸèƒ½åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            æ‰¹å¤„ç†ç»“æœ
        """
        total_videos = len(video_files)
        self.stats["total_videos"] = total_videos
        
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† {total_videos} ä¸ªè§†é¢‘æ–‡ä»¶ (æœ€å¤§å¹¶å‘: {self.max_concurrent})")
        
        if progress_callback:
            progress_callback(0, f"å¼€å§‹å¹¶è¡Œå¤„ç† {total_videos} ä¸ªè§†é¢‘...")
        
        start_time = time.time()
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i, video_file in enumerate(video_files):
            task = self.async_process_video(str(video_file), features)
            tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨as_completedè·å–è¿›åº¦
        results = []
        completed = 0
        
        for coro in asyncio.as_completed(tasks):
            try:
                result = await coro
                results.append(result)
                completed += 1
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if result.get("success"):
                    self.stats["processed_videos"] += 1
                    self.stats["total_slices"] += result.get("slices_count", 0)
                else:
                    self.stats["failed_videos"] += 1
                    self.stats["processing_errors"].append({
                        "video": result.get("video_name", "unknown"),
                        "error": result.get("error", "unknown error")
                    })
                
                # è¿›åº¦å›è°ƒ
                progress = int((completed / total_videos) * 100)
                if progress_callback:
                    progress_callback(
                        progress, 
                        f"å·²å®Œæˆ {completed}/{total_videos} ä¸ªè§†é¢‘ "
                        f"(æˆåŠŸ: {self.stats['processed_videos']}, "
                        f"å¤±è´¥: {self.stats['failed_videos']})"
                    )
                
                logger.info(f"ğŸ“Š è¿›åº¦: {completed}/{total_videos} ({progress}%)")
                
            except Exception as e:
                logger.error(f"å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                results.append({
                    "success": False,
                    "video_name": "unknown",
                    "error": str(e),
                    "slices_count": 0,
                    "slices": []
                })
                completed += 1
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_data = {
            'batch_stats': self.stats.copy(),
            'processing_results': results,
            'parallel_info': {
                'max_concurrent': self.max_concurrent,
                'total_duration_seconds': total_duration,
                'average_time_per_video': total_duration / total_videos if total_videos > 0 else 0,
                'estimated_sequential_time': sum([r.get('processing_time', 94) for r in results if r.get('success')]),
                'time_saved_percentage': 0
            },
            'generated_at': datetime.now().isoformat()
        }
        
        # è®¡ç®—æ—¶é—´èŠ‚çœ
        estimated_sequential = report_data['parallel_info']['estimated_sequential_time']
        if estimated_sequential > 0:
            time_saved = max(0, (estimated_sequential - total_duration) / estimated_sequential * 100)
            report_data['parallel_info']['time_saved_percentage'] = time_saved
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / "parallel_batch_processing_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ‰ å¹¶è¡Œæ‰¹å¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: æˆåŠŸ {self.stats['processed_videos']}/{total_videos} ä¸ªè§†é¢‘")
        logger.info(f"ğŸ¬ æ€»è®¡ç”Ÿæˆ: {self.stats['total_slices']} ä¸ªè§†é¢‘åˆ‡ç‰‡")
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.1f}ç§’")
        logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        if report_data['parallel_info']['time_saved_percentage'] > 0:
            logger.info(f"ğŸš€ æ€§èƒ½æå‡: èŠ‚çœäº† {report_data['parallel_info']['time_saved_percentage']:.1f}% çš„æ—¶é—´!")
        
        return {
            "success": True,
            "stats": self.stats,
            "results": results,
            "report_file": str(report_file),
            "total_duration": total_duration,
            "parallel_info": report_data['parallel_info']
        }
    
    def process_batch_sync(self, input_dir: str, file_patterns: List[str] = None, 
                          features: List[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥æ¥å£çš„å¹¶è¡Œæ‰¹å¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            input_dir: è¾“å…¥ç›®å½•
            file_patterns: æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
            features: åˆ†æåŠŸèƒ½åˆ—è¡¨
            
        Returns:
            æ‰¹å¤„ç†ç»“æœ
        """
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        if not file_patterns:
            file_patterns = ["*.mp4", "*.avi", "*.mov", "*.mkv", "*.wmv", "*.flv"]
        
        video_files = []
        input_path = Path(input_dir)
        
        if not input_path.exists():
            logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return {"success": False, "error": f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}"}
        
        for pattern in file_patterns:
            video_files.extend(input_path.glob(pattern))
        
        if not video_files:
            logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
            return {"success": False, "error": "æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶"}
        
        # è¿è¡Œå¼‚æ­¥æ‰¹å¤„ç†
        def progress_callback(percent, message):
            logger.info(f"è¿›åº¦ {percent}%: {message}")
        
        # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥å‡½æ•°
        return asyncio.run(
            self.parallel_batch_process(video_files, features, progress_callback)
        )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AI Video Master 5.0 - å¹¶è¡Œæ‰¹é‡è§†é¢‘åˆ‡ç‰‡å·¥å…·")
    parser.add_argument("input_dir", help="è¾“å…¥è§†é¢‘ç›®å½•")
    parser.add_argument("-o", "--output", default="./output_slices", help="è¾“å‡ºç›®å½•")
    parser.add_argument("-t", "--temp", default="./temp", help="ä¸´æ—¶ç›®å½•")
    parser.add_argument("-f", "--features", nargs="+", 
                       choices=["shot_detection", "label_detection", "face_detection", "text_detection"],
                       default=["shot_detection"],
                       help="åˆ†æåŠŸèƒ½ (é»˜è®¤ä»…é•œå¤´æ£€æµ‹ï¼Œæ€§èƒ½æœ€ä½³)")
    parser.add_argument("-c", "--concurrent", type=int, default=3,
                       help="è§†é¢‘çº§æœ€å¤§å¹¶å‘æ•° (é»˜è®¤3ï¼Œå»ºè®®ä¸è¶…è¿‡3ä»¥éµå¾ªAPIé…é¢)")
    parser.add_argument("-w", "--ffmpeg-workers", type=int, default=4,
                       help="FFmpegå¹¶è¡Œåˆ‡ç‰‡å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤4ï¼Œå»ºè®®2-8)")
    parser.add_argument("--patterns", nargs="+", 
                       default=["*.mp4", "*.avi", "*.mov", "*.mkv"],
                       help="æ–‡ä»¶åŒ¹é…æ¨¡å¼")
    parser.add_argument("-v", "--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        if not os.path.exists("google_credentials.json"):
            logger.error("è¯·è®¾ç½® GOOGLE_APPLICATION_CREDENTIALS ç¯å¢ƒå˜é‡")
            logger.error("æˆ–å°†Google Cloudå‡­æ®æ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•ä¸‹å¹¶å‘½åä¸º google_credentials.json")
            return 1
    
    try:
        # åˆ›å»ºå¹¶è¡Œå¤„ç†å™¨
        processor = ParallelBatchProcessor(
            output_dir=args.output,
            temp_dir=args.temp,
            max_concurrent=args.concurrent,
            ffmpeg_workers=args.ffmpeg_workers
        )
        
        # æ‰§è¡Œå¹¶è¡Œæ‰¹å¤„ç†
        result = processor.process_batch_sync(
            input_dir=args.input_dir,
            file_patterns=args.patterns,
            features=args.features
        )
        
        if result["success"]:
            print(f"\nâœ… å¹¶è¡Œæ‰¹å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {result['stats']['processed_videos']}/{result['stats']['total_videos']} ä¸ªè§†é¢‘æˆåŠŸ")
            print(f"ğŸ¬ æ€»è®¡ç”Ÿæˆ: {result['stats']['total_slices']} ä¸ªè§†é¢‘åˆ‡ç‰‡")
            print(f"â±ï¸  æ€»è€—æ—¶: {result['total_duration']:.1f}ç§’")
            print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {result['report_file']}")
            
            if result['parallel_info']['time_saved_percentage'] > 0:
                print(f"ğŸš€ æ€§èƒ½æå‡: èŠ‚çœäº† {result['parallel_info']['time_saved_percentage']:.1f}% çš„æ—¶é—´!")
            
            return 0
        else:
            print(f"\nâŒ å¹¶è¡Œæ‰¹å¤„ç†å¤±è´¥: {result['error']}")
            return 1
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
        return 130
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 